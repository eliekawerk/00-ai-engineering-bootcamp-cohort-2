{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0cb319f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42b902a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliekawerk/PycharmProjects/00-ai-engineering-bootcamp-cohort-2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "from langchain_core.messages import AIMessage, convert_to_openai_messages\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Dict, Any, Annotated, List\n",
    "from operator import add\n",
    "\n",
    "\n",
    "import instructor\n",
    "\n",
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6589579",
   "metadata": {},
   "source": [
    "## Create a Coordinator Agent with LiteLLM Router and Feedback model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8724c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Delegation(BaseModel):\n",
    "    agent: str\n",
    "    task: str\n",
    "\n",
    "\n",
    "class CoordinatorAgentResponse(BaseModel):\n",
    "    next_agent: str\n",
    "    plan: List[Delegation]\n",
    "    final_answer: bool\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"coordinator_agent\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1\"},\n",
    ")\n",
    "def coordinator_agent(state, models=[\"gpt-4.1-mini\", \"groq/llama-3.3-70b-versatile\"]):\n",
    "    prompt_template = \"\"\"You are a Coordinator Agent as part of a shopping assistant.\n",
    "\n",
    "Your role is to create plans for solving user queries and delegate the tasks accordingly.\n",
    "You will be given a conversation history, your task is to create a plan for solving the user's query.\n",
    "After the plan is created, you should output the next agent to invoke and the task to be performed by that agent.\n",
    "Once an agent finishes its task, you will be handed the control back, you should then review the conversation history and revise the plan.\n",
    "If there is a sequence of tasks to be performed by a single agent, you should combine them into a single task.\n",
    "\n",
    "The possible agents are:\n",
    "\n",
    "- product_qa_agent: The user is asking a question about a product. This can be a question about available products, their specifications, user reviews etc.\n",
    "- shopping_cart_agent: The user is asking to add or remove items from the shopping cart or questions about the current shopping cart.\n",
    "- warehouse_manager_agent: The user is asking to reserve items from the warehouses or about availability of the items in warehouses.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If next_agent is \"\", final_answer MUST be false\n",
    "(You cannot delegate the task to an agent and return to the user in the same response)\n",
    "- If final_answer is true, next_agent MUST be \"\"\n",
    "(You must wait for agent results before returning to user)\n",
    "- If you need to call other agents before answering, set:\n",
    "next_agent=\"...\", final_answer=false\n",
    "- After receiving agent results, you can then set:\n",
    "next_agent=\"\", final_answer=true\n",
    "- One of the following has to be true:\n",
    "next_agent is \"\" and final_answer is true\n",
    "next_agent is not \"\" and final_answer is false\n",
    "\n",
    "Additional instructions:\n",
    "\n",
    "- Do not route to any agent if the user's query needs clarification. Do it yourself.\n",
    "- Write the plan to the plan field.\n",
    "- Write the next agent to invoke to the next_agent field.\n",
    "- Once you have all the information needed to answer the user's query, you should set the final_answer field to True and output the answer to the user's query.\n",
    "- The final answer to the user query should be a comprehensive answer that explains the actions that were performed to answer the query.\n",
    "- Never set final_answer to true if the plan is not complete.\n",
    "- You should output the next_agent field as well as the plan field.\n",
    "\"\"\"\n",
    "\n",
    "    template = Template(prompt_template)\n",
    "\n",
    "    prompt = template.render()\n",
    "\n",
    "    messages = state.messages\n",
    "\n",
    "    conversation = []\n",
    "\n",
    "    for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "    client = instructor.from_litellm(completion)\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            response, raw_response = client.chat.completions.create_with_completion(\n",
    "                model=model,\n",
    "                response_model=CoordinatorAgentResponse,\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error with model {model}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if response.final_answer:\n",
    "        ai_message = []\n",
    "    else:\n",
    "        ai_message = [AIMessage(content=response.answer)]\n",
    "\n",
    "    return {\n",
    "        \"messages\": ai_message,\n",
    "        \"answer\": response.answer,\n",
    "        \"coordinator_agent\": {\n",
    "            \"iteration\": state.coordinator_agent.iteration + 1,\n",
    "            \"final_answer\": response.final_answer,\n",
    "            \"next_agent\": response.next_agent,\n",
    "            \"plan\": [data.model_dump() for data in response.plan],\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645ffb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: str = Field(description=\"ID of the item used to answer the question.\")\n",
    "    description: str = Field(\n",
    "        description=\"Short description of the item used to answer the question.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class AgentProperties(BaseModel):\n",
    "    iteration: int = 0\n",
    "    final_answer: bool = False\n",
    "    available_tools: List[Dict[str, Any]] = []\n",
    "    tool_calls: List[ToolCall] = []\n",
    "\n",
    "\n",
    "class CoordinatorAgentProperties(BaseModel):\n",
    "    iteration: int = 0\n",
    "    final_answer: bool = False\n",
    "    plan: List[Delegation] = []\n",
    "    next_agent: str = \"\"\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    user_intent: str = \"\"\n",
    "    product_qa_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    shopping_cart_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    coordinator_agent: CoordinatorAgentProperties = Field(\n",
    "        default_factory=AgentProperties\n",
    "    )\n",
    "    answer: str = \"\"\n",
    "    references: Annotated[List[RAGUsedContext], add] = []\n",
    "    user_id: str = \"\"\n",
    "    cart_id: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = State(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the weather today?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = coordinator_agent(\n",
    "    initial_state, models=[\"gpt-4.1-mini\", \"groq/llama-3.3-70b-versatile\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00db6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='I cannot provide weather information. Please ask about products, shopping, or warehouse-related queries.', additional_kwargs={}, response_metadata={})],\n",
       " 'answer': 'I cannot provide weather information. Please ask about products, shopping, or warehouse-related queries.',\n",
       " 'coordinator_agent': {'iteration': 1,\n",
       "  'final_answer': False,\n",
       "  'next_agent': '',\n",
       "  'plan': []}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7a6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = coordinator_agent(\n",
    "    initial_state, models=[\"groq/llama-3.3-70b-versatile\", \"gpt-4.1-mini\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a5510f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='I need to clarify your query. The weather can vary depending on the location. Could you please provide me with the city or region you are interested in?', additional_kwargs={}, response_metadata={})],\n",
       " 'answer': 'I need to clarify your query. The weather can vary depending on the location. Could you please provide me with the city or region you are interested in?',\n",
       " 'coordinator_agent': {'iteration': 1,\n",
       "  'final_answer': False,\n",
       "  'next_agent': '',\n",
       "  'plan': [{'agent': 'CoordinatorAgent', 'task': 'Clarify user query'}]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a67c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
